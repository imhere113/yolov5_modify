diff --git a/data/scripts/get_coco.sh b/data/scripts/get_coco.sh
index 157a0b0..5f7dbc4 100755
--- a/data/scripts/get_coco.sh
+++ b/data/scripts/get_coco.sh
@@ -1,24 +1,56 @@
 #!/bin/bash
-# COCO 2017 dataset http://cocodataset.org
-# Download command: bash data/scripts/get_coco.sh
-# Train command: python train.py --data coco.yaml
-# Default dataset location is next to /yolov5:
-#   /parent_folder
-#     /coco
-#     /yolov5
+# YOLOv5 ðŸš€ by Ultralytics, AGPL-3.0 license
+# Download COCO 2017 dataset http://cocodataset.org
+# Example usage: bash data/scripts/get_coco.sh
+# parent
+# â”œâ”€â”€ yolov5
+# â””â”€â”€ datasets
+#     â””â”€â”€ coco  â† downloads here
+
+# Arguments (optional) Usage: bash data/scripts/get_coco.sh --train --val --test --segments
+if [ "$#" -gt 0 ]; then
+  for opt in "$@"; do
+    case "${opt}" in
+    --train) train=true ;;
+    --val) val=true ;;
+    --test) test=true ;;
+    --segments) segments=true ;;
+    esac
+  done
+else
+  train=true
+  val=true
+  test=false
+  segments=false
+fi
 
 # Download/unzip labels
-d='../' # unzip directory
+d='../datasets' # unzip directory
 url=https://github.com/ultralytics/yolov5/releases/download/v1.0/
-f='coco2017labels.zip'                                                                 # 68 MB
-echo 'Downloading' $url$f ' ...' && curl -L $url$f -o $f && unzip -q $f -d $d && rm $f # download, unzip, remove
+if [ "$segments" == "true" ]; then
+  f='coco2017labels-segments.zip' # 168 MB
+else
+  f='coco2017labels.zip' # 46 MB
+fi
+echo 'Downloading' $url$f ' ...'
+curl -L $url$f -o $f -# && unzip -q $f -d $d && rm $f &
 
 # Download/unzip images
-d='../coco/images' # unzip directory
+d='../datasets/coco/images' # unzip directory
 url=http://images.cocodataset.org/zips/
-f1='train2017.zip' # 19G, 118k images
-f2='val2017.zip'   # 1G, 5k images
-f3='test2017.zip'  # 7G, 41k images (optional)
-for f in $f1 $f2; do
-  echo 'Downloading' $url$f ' ...' && curl -L $url$f -o $f && unzip -q $f -d $d && rm $f # download, unzip, remove
-done
+if [ "$train" == "true" ]; then
+  f='train2017.zip' # 19G, 118k images
+  echo 'Downloading' $url$f '...'
+  curl -L $url$f -o $f -# && unzip -q $f -d $d && rm $f &
+fi
+if [ "$val" == "true" ]; then
+  f='val2017.zip' # 1G, 5k images
+  echo 'Downloading' $url$f '...'
+  curl -L $url$f -o $f -# && unzip -q $f -d $d && rm $f &
+fi
+if [ "$test" == "true" ]; then
+  f='test2017.zip' # 7G, 41k images (optional)
+  echo 'Downloading' $url$f '...'
+  curl -L $url$f -o $f -# && unzip -q $f -d $d && rm $f &
+fi
+wait # finish background tasks
\ No newline at end of file
diff --git a/models/common.py b/models/common.py
index a25707f..a1c90d3 100644
--- a/models/common.py
+++ b/models/common.py
@@ -93,7 +93,7 @@ class SPP(nn.Module):
         c_ = c1 // 2  # hidden channels
         self.cv1 = Conv(c1, c_, 1, 1)
         self.cv2 = Conv(c_ * (len(k) + 1), c2, 1, 1)
-        self.m = nn.ModuleList([nn.MaxPool2d(kernel_size=x, stride=1, padding=x // 2) for x in k])
+        self.m = nn.ModuleList([nn.MaxPool2d(kernel_size=x, stride=1, padding=x // 2, ceil_mode=True) for x in k])
 
     def forward(self, x):
         x = self.cv1(x)
diff --git a/models/yolov5s.yaml b/models/yolov5s.yaml
index aca669d..f47cbab 100644
--- a/models/yolov5s.yaml
+++ b/models/yolov5s.yaml
@@ -1,5 +1,5 @@
 # parameters
-nc: 80  # number of classes
+nc: 3  # number of classes
 depth_multiple: 0.33  # model depth multiple
 width_multiple: 0.50  # layer channel multiple
 
@@ -12,7 +12,8 @@ anchors:
 # YOLOv5 backbone
 backbone:
   # [from, number, module, args]
-  [[-1, 1, Focus, [64, 3]],  # 0-P1/2
+  #[[-1, 1, Focus, [64, 3]],  # 0-P1/2
+  [[-1, 1, Conv, [64, 3, 2]],
    [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4
    [-1, 3, C3, [128]],
    [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8
@@ -27,12 +28,14 @@ backbone:
 # YOLOv5 head
 head:
   [[-1, 1, Conv, [512, 1, 1]],
-   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
+   #[-1, 1, nn.Upsample, [None, 2, 'nearest']],
+   [-1, 1, nn.ConvTranspose2d, [256,256, 2, 2]],
    [[-1, 6], 1, Concat, [1]],  # cat backbone P4
    [-1, 3, C3, [512, False]],  # 13
 
    [-1, 1, Conv, [256, 1, 1]],
-   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
+   #[-1, 1, nn.Upsample, [None, 2, 'nearest']],
+   [-1, 1, nn.ConvTranspose2d, [128,128, 2, 2]],
    [[-1, 4], 1, Concat, [1]],  # cat backbone P3
    [-1, 3, C3, [256, False]],  # 17 (P3/8-small)
 
diff --git a/requirements.txt b/requirements.txt
index 3c23f2b..b626544 100755
--- a/requirements.txt
+++ b/requirements.txt
@@ -21,9 +21,10 @@ seaborn>=0.11.0
 pandas
 
 # export --------------------------------------
-# coremltools==4.0
-# onnx>=1.8.0
-# scikit-learn==0.19.2  # for coreml quantization
+onnx-simplifier
+coremltools==4.0
+onnx>=1.8.0
+scikit-learn==0.19.2  # for coreml quantization
 
 # extras --------------------------------------
 thop  # FLOPS computation
diff --git a/utils/loss.py b/utils/loss.py
index 46051f2..e4788c4 100644
--- a/utils/loss.py
+++ b/utils/loss.py
@@ -153,7 +153,7 @@ def build_targets(p, targets, model):
     det = model.module.model[-1] if is_parallel(model) else model.model[-1]  # Detect() module
     na, nt = det.na, targets.shape[0]  # number of anchors, targets
     tcls, tbox, indices, anch = [], [], [], []
-    gain = torch.ones(7, device=targets.device)  # normalized to gridspace gain
+    gain = torch.ones(7, device=targets.device).long()  # normalized to gridspace gain
     ai = torch.arange(na, device=targets.device).float().view(na, 1).repeat(1, nt)  # same as .repeat_interleave(nt)
     targets = torch.cat((targets.repeat(na, 1, 1), ai[:, :, None]), 2)  # append anchor indices
 
